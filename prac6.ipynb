{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMaBe7jtFysmhGyo7CroRw7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Diksha-Arsule/Wad/blob/main/prac6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mEaLMfCGUwEn"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, models, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset_into_dirs(source_dir: str, dest_root: str, split: Tuple[float, float, float]=(0.5, 0.25, 0.25), seed: int = 42):\n",
        "    \"\"\"\n",
        "    Copy images from source_dir/class_x/* into dest_root/{train,valid,test}/class_x/\n",
        "    according to split ratios. Keeps file extensions and names.\n",
        "    \"\"\"\n",
        "    assert sum(split) == 1.0, \"split must sum to 1.0\"\n",
        "    random.seed(seed)\n",
        "    source = Path(source_dir)\n",
        "    dest_root = Path(dest_root)\n",
        "    train_dir = dest_root / \"train\"\n",
        "    valid_dir = dest_root / \"valid\"\n",
        "    test_dir  = dest_root / \"test\"\n",
        "    for d in (train_dir, valid_dir, test_dir):\n",
        "        d.mkdir(parents=True, exist_ok=True)\n",
        "    classes = [p for p in source.iterdir() if p.is_dir()]\n",
        "    if not classes:\n",
        "        raise RuntimeError(f\"No class subdirectories found in {source_dir}\")\n",
        "\n",
        "    for cls_path in classes:\n",
        "        cls_name = cls_path.name\n",
        "        images = [p for p in cls_path.iterdir() if p.is_file()]\n",
        "        if not images:\n",
        "            continue\n",
        "        random.shuffle(images)\n",
        "        n = len(images)\n",
        "        n_train = int(split[0] * n)\n",
        "        n_valid = int(split[1] * n)\n",
        "        # remainder to test\n",
        "        n_test = n - n_train - n_valid\n",
        "\n",
        "        assignments = {\n",
        "            train_dir / cls_name: images[:n_train],\n",
        "            valid_dir / cls_name: images[n_train:n_train + n_valid],\n",
        "            test_dir  / cls_name: images[n_train + n_valid:]\n",
        "        }\n",
        "\n",
        "        for out_dir, files in assignments.items():\n",
        "            out_dir.mkdir(parents=True, exist_ok=True)\n",
        "            for src_path in files:\n",
        "                dst_path = out_dir / src_path.name\n",
        "                # copy if not exists (to allow restarting)\n",
        "                if not dst_path.exists():\n",
        "                    shutil.copy2(src_path, dst_path)\n",
        "\n",
        "    print(f\"Dataset split into: {train_dir}, {valid_dir}, {test_dir}\")"
      ],
      "metadata": {
        "id": "kzEZp1WPWENr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dataloaders(datadir: str, batch_size: int = 32, num_workers: int = 4) -> Tuple[Dict[str, DataLoader], Dict[str, datasets.ImageFolder]]:\n",
        "    image_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
        "            transforms.RandomRotation(degrees=15),\n",
        "            transforms.ColorJitter(),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.CenterCrop(size=224),  # ImageNet standard\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                 [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'valid': transforms.Compose([\n",
        "            transforms.Resize(size=256),\n",
        "            transforms.CenterCrop(size=224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                 [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'test': transforms.Compose([\n",
        "            transforms.Resize(size=256),\n",
        "            transforms.CenterCrop(size=224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                 [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "    data_dirs = { 'train': os.path.join(datadir, 'train'),\n",
        "                  'valid': os.path.join(datadir, 'valid'),\n",
        "                  'test' : os.path.join(datadir, 'test') }\n",
        "\n",
        "    datasets_dict = {\n",
        "        x: datasets.ImageFolder(root=data_dirs[x], transform=image_transforms[x])\n",
        "        for x in ['train', 'valid', 'test']\n",
        "    }\n",
        "    dataloaders = {\n",
        "        'train': DataLoader(datasets_dict['train'], batch_size=batch_size, shuffle=True, num_workers=num_workers),\n",
        "        'val':   DataLoader(datasets_dict['valid'], batch_size=batch_size, shuffle=False, num_workers=num_workers),\n",
        "        'test':  DataLoader(datasets_dict['test'], batch_size=batch_size, shuffle=False, num_workers=num_workers),\n",
        "    }\n",
        "    return dataloaders, datasets_dict\n",
        "\n"
      ],
      "metadata": {
        "id": "ViVVznsgW4Wy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_model(num_classes: int, device: torch.device) -> nn.Module:\n",
        "    # Load pretrained VGG16\n",
        "    model = models.vgg16(pretrained=True)\n",
        "\n",
        "    # Freeze all parameters initially\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    if isinstance(model.classifier[6], nn.Linear):\n",
        "        n_inputs = model.classifier[6].in_features\n",
        "    else:\n",
        "        # fallback: flatten size after features -> 25088 for standard VGG16 224x224\n",
        "        n_inputs = 25088\n",
        "\n",
        "   # Ensure only classifier[6] parameters are trainable:\n",
        "    for name, param in model.named_parameters():\n",
        "        # any parameter in classifier[6] should have requires_grad=True\n",
        "        if name.startswith('classifier.6'):\n",
        "            param.requires_grad = True\n",
        "        else:\n",
        "            param.requires_grad = False\n",
        "\n",
        "    model = model.to(device)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "3wL2hpu5YNRC"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model: nn.Module, dataloaders: Dict[str, DataLoader], dataset_sizes: Dict[str, int],\n",
        "                device: torch.device, epochs: int = 10, lr: float = 1e-3, save_path: str = \"best_vgg16.pth\"):\n",
        "    # Only parameters that require grad are passed to optimizer\n",
        "    params_to_update = [p for p in model.parameters() if p.requires_grad]\n",
        "    optimizer = torch.optim.Adam(params_to_update, lr=lr)\n",
        "    criterion = nn.NLLLoss()  # because model outputs LogSoftmax\n",
        "\n",
        "    best_acc = 0.0\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"\\nEpoch {epoch}/{epochs}\")\n",
        "        print(\"-\" * 20)\n",
        "\n",
        "    # Each epoch has train and val phases\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            loader = dataloaders['train'] if phase == 'train' else dataloaders['val']\n",
        "            for inputs, labels in loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data).item()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes['train'] if phase == 'train' else running_loss / dataset_sizes['valid']\n",
        "            epoch_acc  = running_corrects / dataset_sizes['train'] if phase == 'train' else running_corrects / dataset_sizes['valid']\n",
        "\n",
        "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "             # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                torch.save({\n",
        "                    'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'best_acc': best_acc\n",
        "                }, save_path)\n",
        "                print(f\"Saved best model with val acc: {best_acc:.4f}\")\n",
        "\n",
        "    print(f\"\\nTraining complete. Best val Acc: {best_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "lMg4oOEoYfs-"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_on_test(model: nn.Module, dataloader: DataLoader, device: torch.device):\n",
        "    model.eval()\n",
        "    running_corrects = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds == labels.data).item()\n",
        "            total += inputs.size(0)\n",
        "    acc = running_corrects / total if total > 0 else 0.0\n",
        "    print(f\"Test Accuracy: {acc:.4f}\")\n",
        "    return acc"
      ],
      "metadata": {
        "id": "nRoS_7tWY3la"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Transfer learning with VGG16\")\n",
        "    parser.add_argument('--source_dir', type=str, required=True,\n",
        "                        help=\"Source dataset root with class subfolders. e.g. ./caltech_images\")\n",
        "    parser.add_argument('--work_dir', type=str, default='./datadir',\n",
        "                        help=\"Destination root where train/valid/test folders will be created\")\n",
        "    parser.add_argument('--batch_size', type=int, default=32)\n",
        "    parser.add_argument('--epochs', type=int, default=8)\n",
        "    parser.add_argument('--lr', type=float, default=1e-3)\n",
        "    parser.add_argument('--num_workers', type=int, default=4)\n",
        "    parser.add_argument('--seed', type=int, default=42)\n",
        "    parser.add_argument('--save_path', type=str, default='best_vgg16.pth')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "     # 1) Split and copy the dataset into train/valid/test\n",
        "    split_dataset_into_dirs(args.source_dir, args.work_dir, split=(0.5, 0.25, 0.25), seed=args.seed)\n",
        "\n",
        "    # 2) Prepare dataloaders\n",
        "    dataloaders, datasets_dict = build_dataloaders(args.work_dir, batch_size=args.batch_size, num_workers=args.num_workers)\n",
        "    dataset_sizes = {'train': len(datasets_dict['train']), 'valid': len(datasets_dict['valid']), 'test': len(datasets_dict['test'])}\n",
        "    class_names = datasets_dict['train'].classes\n",
        "    num_classes = len(class_names)\n",
        "    print(f\"Found classes: {class_names}, num_classes={num_classes}\")\n",
        "    print(f\"Dataset sizes: {dataset_sizes}\")\n",
        "\n",
        "    # 3) Device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # 4) Prepare model\n",
        "    model = prepare_model(num_classes=num_classes, device=device)\n",
        "    print(\"Model prepared. Trainable parameters:\")\n",
        "    for name, param in model.named_parameters():\n",
        "        if param.requires_grad:\n",
        "            print(\"  \", name, param.size())\n",
        "\n",
        "     # 5) Train\n",
        "    train_model(model, dataloaders, dataset_sizes, device, epochs=args.epochs, lr=args.lr, save_path=args.save_path)\n",
        "\n",
        "     # 6) Load best model and evaluate on test\n",
        "    if os.path.exists(args.save_path):\n",
        "        ckpt = torch.load(args.save_path, map_location=device)\n",
        "        model.load_state_dict(ckpt['model_state_dict'])\n",
        "        print(f\"Loaded best model from epoch {ckpt.get('epoch', '?')} with val acc {ckpt.get('best_acc', '?')}\")\n",
        "    evaluate_on_test(model, dataloaders['test'], device)\n",
        "\n"
      ],
      "metadata": {
        "id": "Oa0DXZWmZFIU"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}